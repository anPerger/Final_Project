{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing, feature_selection, metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import lime\n",
    "from lime import lime_text\n",
    "stop = stopwords.words('english')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   country                                        description  \\\n",
       "0           0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2           2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3           3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4           4        US  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3                Reserve Late Harvest      87   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                NaN       Kerin O’Keefe   \n",
       "1                  NaN                NaN          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  \n",
       "2      Pinot Gris            Rainstorm  \n",
       "3        Riesling           St. Julian  \n",
       "4      Pinot Noir         Sweet Cheeks  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_wines = pd.read_csv('Data/winemag-data-130k-v2.csv')\n",
    "all_wines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129966</th>\n",
       "      <td>Notes of honeysuckle and cantaloupe sweeten th...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129967</th>\n",
       "      <td>Citation is given as much as a decade of bottl...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129968</th>\n",
       "      <td>Well-drained gravel soil gives this wine its c...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129969</th>\n",
       "      <td>A dry style of Pinot Gris, this is crisp with ...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129970</th>\n",
       "      <td>Big, rich and off-dry, this is powered by inte...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129971 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description  points\n",
       "0       Aromas include tropical fruit, broom, brimston...      87\n",
       "1       This is ripe and fruity, a wine that is smooth...      87\n",
       "2       Tart and snappy, the flavors of lime flesh and...      87\n",
       "3       Pineapple rind, lemon pith and orange blossom ...      87\n",
       "4       Much like the regular bottling from 2012, this...      87\n",
       "...                                                   ...     ...\n",
       "129966  Notes of honeysuckle and cantaloupe sweeten th...      90\n",
       "129967  Citation is given as much as a decade of bottl...      90\n",
       "129968  Well-drained gravel soil gives this wine its c...      90\n",
       "129969  A dry style of Pinot Gris, this is crisp with ...      90\n",
       "129970  Big, rich and off-dry, this is powered by inte...      90\n",
       "\n",
       "[129971 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_wines = all_wines.drop(columns=['Unnamed: 0', 'taster_twitter_handle', 'region_2', 'price', 'province',\n",
    "                                     'region_1', 'taster_name', 'title', 'variety', 'winery', 'country', 'designation'])\n",
    "clean_wines = clean_wines.dropna()\n",
    "clean_wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "clean_wines['points'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    129971.000000\n",
       "mean         88.447138\n",
       "std           3.039730\n",
       "min          80.000000\n",
       "25%          86.000000\n",
       "50%          88.000000\n",
       "75%          91.000000\n",
       "max         100.000000\n",
       "Name: points, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_wines['points'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129966</th>\n",
       "      <td>Notes of honeysuckle and cantaloupe sweeten th...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129967</th>\n",
       "      <td>Citation is given as much as a decade of bottl...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129968</th>\n",
       "      <td>Well-drained gravel soil gives this wine its c...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129969</th>\n",
       "      <td>A dry style of Pinot Gris, this is crisp with ...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129970</th>\n",
       "      <td>Big, rich and off-dry, this is powered by inte...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119955 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description  points\n",
       "0       Aromas include tropical fruit, broom, brimston...      87\n",
       "1       This is ripe and fruity, a wine that is smooth...      87\n",
       "2       Tart and snappy, the flavors of lime flesh and...      87\n",
       "3       Pineapple rind, lemon pith and orange blossom ...      87\n",
       "4       Much like the regular bottling from 2012, this...      87\n",
       "...                                                   ...     ...\n",
       "129966  Notes of honeysuckle and cantaloupe sweeten th...      90\n",
       "129967  Citation is given as much as a decade of bottl...      90\n",
       "129968  Well-drained gravel soil gives this wine its c...      90\n",
       "129969  A dry style of Pinot Gris, this is crisp with ...      90\n",
       "129970  Big, rich and off-dry, this is powered by inte...      90\n",
       "\n",
       "[119955 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_wines = clean_wines.drop_duplicates('description')\n",
    "clean_wines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\audri\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129966</th>\n",
       "      <td>Notes of honeysuckle and cantaloupe sweeten th...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129967</th>\n",
       "      <td>Citation is given as much as a decade of bottl...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129968</th>\n",
       "      <td>Well-drained gravel soil gives this wine its c...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129969</th>\n",
       "      <td>A dry style of Pinot Gris, this is crisp with ...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129970</th>\n",
       "      <td>Big, rich and off-dry, this is powered by inte...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119955 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description  points grade\n",
       "0       Aromas include tropical fruit, broom, brimston...      87     C\n",
       "1       This is ripe and fruity, a wine that is smooth...      87     C\n",
       "2       Tart and snappy, the flavors of lime flesh and...      87     C\n",
       "3       Pineapple rind, lemon pith and orange blossom ...      87     C\n",
       "4       Much like the regular bottling from 2012, this...      87     C\n",
       "...                                                   ...     ...   ...\n",
       "129966  Notes of honeysuckle and cantaloupe sweeten th...      90     B\n",
       "129967  Citation is given as much as a decade of bottl...      90     B\n",
       "129968  Well-drained gravel soil gives this wine its c...      90     B\n",
       "129969  A dry style of Pinot Gris, this is crisp with ...      90     B\n",
       "129970  Big, rich and off-dry, this is powered by inte...      90     B\n",
       "\n",
       "[119955 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_wines['grade'] = clean_wines['points'].apply(lambda x: 'A' if x >= 92 else\n",
    "                                                             'B' if x >= 89 else\n",
    "                                                             'C' if x >= 86 else\n",
    "                                                             'F')\n",
    "clean_wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\audri\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>grade</th>\n",
       "      <th>good_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129966</th>\n",
       "      <td>Notes of honeysuckle and cantaloupe sweeten th...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129967</th>\n",
       "      <td>Citation is given as much as a decade of bottl...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129968</th>\n",
       "      <td>Well-drained gravel soil gives this wine its c...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129969</th>\n",
       "      <td>A dry style of Pinot Gris, this is crisp with ...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129970</th>\n",
       "      <td>Big, rich and off-dry, this is powered by inte...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119955 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description  points grade  \\\n",
       "0       Aromas include tropical fruit, broom, brimston...      87     C   \n",
       "1       This is ripe and fruity, a wine that is smooth...      87     C   \n",
       "2       Tart and snappy, the flavors of lime flesh and...      87     C   \n",
       "3       Pineapple rind, lemon pith and orange blossom ...      87     C   \n",
       "4       Much like the regular bottling from 2012, this...      87     C   \n",
       "...                                                   ...     ...   ...   \n",
       "129966  Notes of honeysuckle and cantaloupe sweeten th...      90     B   \n",
       "129967  Citation is given as much as a decade of bottl...      90     B   \n",
       "129968  Well-drained gravel soil gives this wine its c...      90     B   \n",
       "129969  A dry style of Pinot Gris, this is crisp with ...      90     B   \n",
       "129970  Big, rich and off-dry, this is powered by inte...      90     B   \n",
       "\n",
       "       good_bad  \n",
       "0           Bad  \n",
       "1           Bad  \n",
       "2           Bad  \n",
       "3           Bad  \n",
       "4           Bad  \n",
       "...         ...  \n",
       "129966     Good  \n",
       "129967     Good  \n",
       "129968     Good  \n",
       "129969     Good  \n",
       "129970     Good  \n",
       "\n",
       "[119955 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_wines['good_bad'] = clean_wines['points'].apply(lambda x: 'Good' if x >= 88 else\n",
    "                                                     'Bad')\n",
    "clean_wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "lst_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\audri\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>grade</th>\n",
       "      <th>good_bad</th>\n",
       "      <th>description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "      <td>aroma include tropical fruit broom brimstone d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "      <td>ripe fruity wine smooth still structured firm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "      <td>tart snappy flavor lime flesh rind dominate gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "      <td>pineapple rind lemon pith orange blossom start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "      <td>much like regular bottling 2012 come across ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  points grade good_bad  \\\n",
       "0  Aromas include tropical fruit, broom, brimston...      87     C      Bad   \n",
       "1  This is ripe and fruity, a wine that is smooth...      87     C      Bad   \n",
       "2  Tart and snappy, the flavors of lime flesh and...      87     C      Bad   \n",
       "3  Pineapple rind, lemon pith and orange blossom ...      87     C      Bad   \n",
       "4  Much like the regular bottling from 2012, this...      87     C      Bad   \n",
       "\n",
       "                                   description_clean  \n",
       "0  aroma include tropical fruit broom brimstone d...  \n",
       "1  ripe fruity wine smooth still structured firm ...  \n",
       "2  tart snappy flavor lime flesh rind dominate gr...  \n",
       "3  pineapple rind lemon pith orange blossom start...  \n",
       "4  much like regular bottling 2012 come across ra...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_wines[\"description_clean\"] = clean_wines[\"description\"].apply(lambda x: \n",
    "          utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, \n",
    "          lst_stopwords=lst_stopwords))\n",
    "clean_wines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\audri\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>grade</th>\n",
       "      <th>good_bad</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>description_cleaner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "      <td>aroma include tropical fruit broom brimstone d...</td>\n",
       "      <td>aroma include tropical fruit broom brimstone d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "      <td>ripe fruity wine smooth still structured firm ...</td>\n",
       "      <td>ripe fruity wine smooth still structured firm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "      <td>tart snappy flavor lime flesh rind dominate gr...</td>\n",
       "      <td>tart snappy flavor lime flesh rind dominate gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "      <td>pineapple rind lemon pith orange blossom start...</td>\n",
       "      <td>pineapple rind lemon pith orange blossom start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>87</td>\n",
       "      <td>C</td>\n",
       "      <td>Bad</td>\n",
       "      <td>much like regular bottling 2012 come across ra...</td>\n",
       "      <td>much like regular bottling  come across rather...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129966</th>\n",
       "      <td>Notes of honeysuckle and cantaloupe sweeten th...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "      <td>Good</td>\n",
       "      <td>note honeysuckle cantaloupe sweeten deliciousl...</td>\n",
       "      <td>note honeysuckle cantaloupe sweeten deliciousl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129967</th>\n",
       "      <td>Citation is given as much as a decade of bottl...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "      <td>Good</td>\n",
       "      <td>citation given much decade bottle age prior re...</td>\n",
       "      <td>citation given much decade bottle age prior re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129968</th>\n",
       "      <td>Well-drained gravel soil gives this wine its c...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "      <td>Good</td>\n",
       "      <td>welldrained gravel soil give wine crisp dry ch...</td>\n",
       "      <td>welldrained gravel soil give wine crisp dry ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129969</th>\n",
       "      <td>A dry style of Pinot Gris, this is crisp with ...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "      <td>Good</td>\n",
       "      <td>dry style pinot gris crisp acidity also weight...</td>\n",
       "      <td>dry style pinot gris crisp acidity also weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129970</th>\n",
       "      <td>Big, rich and off-dry, this is powered by inte...</td>\n",
       "      <td>90</td>\n",
       "      <td>B</td>\n",
       "      <td>Good</td>\n",
       "      <td>big rich offdry powered intense spiciness roun...</td>\n",
       "      <td>big rich offdry powered intense spiciness roun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119955 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description  points grade  \\\n",
       "0       Aromas include tropical fruit, broom, brimston...      87     C   \n",
       "1       This is ripe and fruity, a wine that is smooth...      87     C   \n",
       "2       Tart and snappy, the flavors of lime flesh and...      87     C   \n",
       "3       Pineapple rind, lemon pith and orange blossom ...      87     C   \n",
       "4       Much like the regular bottling from 2012, this...      87     C   \n",
       "...                                                   ...     ...   ...   \n",
       "129966  Notes of honeysuckle and cantaloupe sweeten th...      90     B   \n",
       "129967  Citation is given as much as a decade of bottl...      90     B   \n",
       "129968  Well-drained gravel soil gives this wine its c...      90     B   \n",
       "129969  A dry style of Pinot Gris, this is crisp with ...      90     B   \n",
       "129970  Big, rich and off-dry, this is powered by inte...      90     B   \n",
       "\n",
       "       good_bad                                  description_clean  \\\n",
       "0           Bad  aroma include tropical fruit broom brimstone d...   \n",
       "1           Bad  ripe fruity wine smooth still structured firm ...   \n",
       "2           Bad  tart snappy flavor lime flesh rind dominate gr...   \n",
       "3           Bad  pineapple rind lemon pith orange blossom start...   \n",
       "4           Bad  much like regular bottling 2012 come across ra...   \n",
       "...         ...                                                ...   \n",
       "129966     Good  note honeysuckle cantaloupe sweeten deliciousl...   \n",
       "129967     Good  citation given much decade bottle age prior re...   \n",
       "129968     Good  welldrained gravel soil give wine crisp dry ch...   \n",
       "129969     Good  dry style pinot gris crisp acidity also weight...   \n",
       "129970     Good  big rich offdry powered intense spiciness roun...   \n",
       "\n",
       "                                      description_cleaner  \n",
       "0       aroma include tropical fruit broom brimstone d...  \n",
       "1       ripe fruity wine smooth still structured firm ...  \n",
       "2       tart snappy flavor lime flesh rind dominate gr...  \n",
       "3       pineapple rind lemon pith orange blossom start...  \n",
       "4       much like regular bottling  come across rather...  \n",
       "...                                                   ...  \n",
       "129966  note honeysuckle cantaloupe sweeten deliciousl...  \n",
       "129967  citation given much decade bottle age prior re...  \n",
       "129968  welldrained gravel soil give wine crisp dry ch...  \n",
       "129969  dry style pinot gris crisp acidity also weight...  \n",
       "129970  big rich offdry powered intense spiciness roun...  \n",
       "\n",
       "[119955 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_texts = clean_wines['description_clean']\n",
    "def no_number_preprocessor(tokens):\n",
    "    r = re.sub('(\\d)+', '', tokens.lower())\n",
    "    # This alternative just removes numbers:\n",
    "    # r = re.sub('(\\d)+', '', tokens.lower())\n",
    "    return r\n",
    "no_num_txts = []\n",
    "for t in list_of_texts:\n",
    "    no_num_t = no_number_preprocessor(t)\n",
    "    no_num_txts.append(no_num_t)\n",
    "\n",
    "clean_wines['description_cleaner'] = no_num_txts\n",
    "clean_wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_descriptions = clean_wines['description_cleaner']\n",
    "adjs = []\n",
    "for t in list_of_descriptions:\n",
    "    is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "    tokenized = nltk.word_tokenize(t)\n",
    "    adj = [word for (word, pos) in nltk.pos_tag(tokenized) if is_adj(pos)]\n",
    "    adjs.append(adj)\n",
    "# clean_wines['adjs'] = adjs\n",
    "# clean_wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adj_string_list = []\n",
    "for x in adjs:\n",
    "    all_adj_string = \"\"\n",
    "    for y in x:\n",
    "        all_adj_string = all_adj_string + \" \" + y\n",
    "    \n",
    "    all_adj_string_list.append(all_adj_string)\n",
    "    \n",
    "all_adj_string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_wines['adjectives'] = all_adj_string_list\n",
    "clean_wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = clean_wines[['points', 'grade', 'good_bad', 'description_clean', 'description_cleaner', 'adjectives']]\n",
    "dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.to_csv('Data/clean_wines_with_adjectives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = pd.read_csv('Data/clean_wines_with_adjectives.csv')\n",
    "dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.dropna()\n",
    "dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf_train, dtf_test = model_selection.train_test_split(dtf, test_size=0.3)\n",
    "## get target\n",
    "y_train = dtf_train[\"good_bad\"].values\n",
    "y_test = dtf_test[\"good_bad\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.CountVectorizer(max_features=10000, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dtf_train[\"description_cleaner\"]\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(corpus)\n",
    "dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(X_train.todense()[:,np.random.randint(0,X_train.shape[1],100)]==0, vmin=0, vmax=1, cbar=False).set_title('Sparse Matrix Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dtf_train[\"good_bad\"]\n",
    "X_names = vectorizer.get_feature_names()\n",
    "p_value_limit = 0.95\n",
    "dtf_features = pd.DataFrame()\n",
    "for cat in np.unique(y):\n",
    "    chi2, p = feature_selection.chi2(X_train, y==cat)\n",
    "    dtf_features = dtf_features.append(pd.DataFrame(\n",
    "                   {\"feature\":X_names, \"score\":1-p, \"good_bad\":cat}))\n",
    "    dtf_features = dtf_features.sort_values([\"good_bad\",\"score\"], \n",
    "                    ascending=[True,False])\n",
    "    dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n",
    "X_names = dtf_features[\"feature\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in np.unique(y):\n",
    "   print(\"# {}:\".format(cat))\n",
    "   print(\"  . selected features:\",\n",
    "         len(dtf_features[dtf_features[\"good_bad\"]==cat]))\n",
    "   print(\"  . top features:\", \",\".join(\n",
    "dtf_features[dtf_features[\"good_bad\"]==cat][\"feature\"].values[:30]))\n",
    "   print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(vocabulary=X_names)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(corpus)\n",
    "dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipeline\n",
    "model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifier)])\n",
    "## train classifier\n",
    "model[\"classifier\"].fit(X_train, y_train)\n",
    "## test\n",
    "X_test = dtf_test[\"description_cleaner\"].values\n",
    "predicted = model.predict(X_test)\n",
    "predicted_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classes = np.unique(y_test)\n",
    "y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test_array, predicted_prob, \n",
    "                            multi_class=\"one_vs_one\")\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "                           predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "              label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select observation\n",
    "i = 19\n",
    "txt_instance = dtf_test[\"description_cleaner\"].iloc[i]\n",
    "## check true value and predicted value\n",
    "print(\"True:\", y_test[i], \"--> Pred:\", predicted[i], \"| Prob:\", round(np.max(predicted_prob[i]),2))\n",
    "## show explanation\n",
    "explainer = lime_text.LimeTextExplainer(class_names=\n",
    "             np.unique(y_train))\n",
    "explained = explainer.explain_instance(txt_instance, \n",
    "             model.predict_proba, num_features=5)\n",
    "explained.show_in_notebook(text=txt_instance, predict_proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'prediction' : predicted, \n",
    "     'actual' : y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_predictions_df = pd.DataFrame(data=d)\n",
    "text_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_predictions_df.to_csv('Data/text_predictions_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf_train, dtf_test = model_selection.train_test_split(dtf, test_size=0.3)\n",
    "## get target\n",
    "y_train = dtf_train[\"grade\"].values\n",
    "y_test = dtf_test[\"grade\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.CountVectorizer(max_features=10000, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dtf_train[\"description_cleaner\"]\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(corpus)\n",
    "dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(X_train.todense()[:,np.random.randint(0,X_train.shape[1],100)]==0, vmin=0, vmax=1, cbar=False).set_title('Sparse Matrix Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dtf_train[\"grade\"]\n",
    "X_names = vectorizer.get_feature_names()\n",
    "p_value_limit = 0.95\n",
    "dtf_features = pd.DataFrame()\n",
    "for cat in np.unique(y):\n",
    "    chi2, p = feature_selection.chi2(X_train, y==cat)\n",
    "    dtf_features = dtf_features.append(pd.DataFrame(\n",
    "                   {\"feature\":X_names, \"score\":1-p, \"grade\":cat}))\n",
    "    dtf_features = dtf_features.sort_values([\"grade\",\"score\"], \n",
    "                    ascending=[True,False])\n",
    "    dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n",
    "X_names = dtf_features[\"feature\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in np.unique(y):\n",
    "   print(\"# {}:\".format(cat))\n",
    "   print(\"  . selected features:\",\n",
    "         len(dtf_features[dtf_features[\"grade\"]==cat]))\n",
    "   print(\"  . top features:\", \",\".join(\n",
    "dtf_features[dtf_features[\"grade\"]==cat][\"feature\"].values[:30]))\n",
    "   print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(vocabulary=X_names)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(corpus)\n",
    "dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipeline\n",
    "model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifier)])\n",
    "## train classifier\n",
    "model[\"classifier\"].fit(X_train, y_train)\n",
    "## test\n",
    "X_test = dtf_test[\"description_cleaner\"].values\n",
    "predicted = model.predict(X_test)\n",
    "predicted_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_test)\n",
    "y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test_array, predicted_prob, \n",
    "                            multi_class=\"one_vs_rest\")\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "                           predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "              label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select observation\n",
    "i = 13\n",
    "txt_instance = dtf_test[\"description_cleaner\"].iloc[i]\n",
    "## check true value and predicted value\n",
    "print(\"True:\", y_test[i], \"--> Pred:\", predicted[i], \"| Prob:\", round(np.max(predicted_prob[i]),2))\n",
    "## show explanation\n",
    "explainer = lime_text.LimeTextExplainer(class_names=\n",
    "             np.unique(y_train))\n",
    "explained = explainer.explain_instance(txt_instance, \n",
    "             model.predict_proba, num_features=5)\n",
    "explained.show_in_notebook(text=txt_instance, predict_proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'prediction' : predicted, \n",
    "     'actual' : y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_predictions_df = pd.DataFrame(data=d)\n",
    "text_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_predictions_df.to_csv('Data/text_predictions_grades.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all garbage code from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtf_train, dtf_test = model_selection.train_test_split(dtf, test_size=0.3)\n",
    "# ## get target\n",
    "# y_train = dtf_train[\"good_bad\"].values\n",
    "# y_test = dtf_test[\"good_bad\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = feature_extraction.text.CountVectorizer(max_features=10000, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = dtf_train[\"adjectives\"]\n",
    "# vectorizer.fit(corpus)\n",
    "# X_train = vectorizer.transform(corpus)\n",
    "# dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(X_train.todense()[:,np.random.randint(0,X_train.shape[1],100)]==0, vmin=0, vmax=1, cbar=False).set_title('Sparse Matrix Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = dtf_train[\"good_bad\"]\n",
    "# X_names = vectorizer.get_feature_names()\n",
    "# p_value_limit = 0.95\n",
    "# dtf_features = pd.DataFrame()\n",
    "# for cat in np.unique(y):\n",
    "#     chi2, p = feature_selection.chi2(X_train, y==cat)\n",
    "#     dtf_features = dtf_features.append(pd.DataFrame(\n",
    "#                    {\"feature\":X_names, \"score\":1-p, \"good_bad\":cat}))\n",
    "#     dtf_features = dtf_features.sort_values([\"good_bad\",\"score\"], \n",
    "#                     ascending=[True,False])\n",
    "#     dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n",
    "# X_names = dtf_features[\"feature\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cat in np.unique(y):\n",
    "#    print(\"# {}:\".format(cat))\n",
    "#    print(\"  . selected features:\",\n",
    "#          len(dtf_features[dtf_features[\"good_bad\"]==cat]))\n",
    "#    print(\"  . top features:\", \",\".join(\n",
    "# dtf_features[dtf_features[\"good_bad\"]==cat][\"feature\"].values[:30]))\n",
    "#    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = feature_extraction.text.TfidfVectorizer(vocabulary=X_names)\n",
    "# vectorizer.fit(corpus)\n",
    "# X_train = vectorizer.transform(corpus)\n",
    "# dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## pipeline\n",
    "# model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "#                            (\"classifier\", classifier)])\n",
    "# ## train classifier\n",
    "# model[\"classifier\"].fit(X_train, y_train)\n",
    "# ## test\n",
    "# X_test = dtf_test[\"adjectives\"].values\n",
    "# predicted = model.predict(X_test)\n",
    "# predicted_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = np.unique(y_test)\n",
    "# y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "# y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "# auc = metrics.roc_auc_score(y_test_array, predicted_prob, \n",
    "#                             multi_class=\"one_vs_one\")\n",
    "# print(\"Accuracy:\",  round(accuracy,2))\n",
    "# print(\"Auc:\", round(auc,2))\n",
    "# print(\"Detail:\")\n",
    "# print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = metrics.confusion_matrix(y_test, predicted)\n",
    "# fig, ax = plt.subplots()\n",
    "# sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "#             cbar=False)\n",
    "# ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "#        yticklabels=classes, title=\"Confusion matrix\")\n",
    "# plt.yticks(rotation=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "# for i in range(len(classes)):\n",
    "#     fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "#                            predicted_prob[:,i])\n",
    "#     ax[0].plot(fpr, tpr, lw=3, \n",
    "#               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "#                               metrics.auc(fpr, tpr))\n",
    "#                )\n",
    "# ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "# ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "#           xlabel='False Positive Rate', \n",
    "#           ylabel=\"True Positive Rate (Recall)\", \n",
    "#           title=\"Receiver operating characteristic\")\n",
    "# ax[0].legend(loc=\"lower right\")\n",
    "# ax[0].grid(True)\n",
    "\n",
    "# for i in range(len(classes)):\n",
    "#     precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "#                  y_test_array[:,i], predicted_prob[:,i])\n",
    "#     ax[1].plot(recall, precision, lw=3, \n",
    "#                label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "#                                   metrics.auc(recall, precision))\n",
    "#               )\n",
    "# ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "#           ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "# ax[1].legend(loc=\"best\")\n",
    "# ax[1].grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## select observation\n",
    "# i = 17\n",
    "# txt_instance = dtf_test[\"description_cleaner\"].iloc[i]\n",
    "# ## check true value and predicted value\n",
    "# print(\"True:\", y_test[i], \"--> Pred:\", predicted[i], \"| Prob:\", round(np.max(predicted_prob[i]),2))\n",
    "# ## show explanation\n",
    "# explainer = lime_text.LimeTextExplainer(class_names=\n",
    "#              np.unique(y_train))\n",
    "# explained = explainer.explain_instance(txt_instance, \n",
    "#              model.predict_proba, num_features=5)\n",
    "# explained.show_in_notebook(text=txt_instance, predict_proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {'prediction' : predicted, \n",
    "#      'actual' : y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_predictions_df = pd.DataFrame(data=d)\n",
    "# adj_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_predictions_df.to_csv('Data/adj_predictions_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtf_train, dtf_test = model_selection.train_test_split(dtf, test_size=0.3)\n",
    "# ## get target\n",
    "# y_train = dtf_train[\"grade\"].values\n",
    "# y_test = dtf_test[\"grade\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = feature_extraction.text.CountVectorizer(max_features=10000, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = dtf_train[\"adjectives\"]\n",
    "# vectorizer.fit(corpus)\n",
    "# X_train = vectorizer.transform(corpus)\n",
    "# dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(X_train.todense()[:,np.random.randint(0,X_train.shape[1],100)]==0, vmin=0, vmax=1, cbar=False).set_title('Sparse Matrix Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = dtf_train[\"grade\"]\n",
    "# X_names = vectorizer.get_feature_names()\n",
    "# p_value_limit = 0.95\n",
    "# dtf_features = pd.DataFrame()\n",
    "# for cat in np.unique(y):\n",
    "#     chi2, p = feature_selection.chi2(X_train, y==cat)\n",
    "#     dtf_features = dtf_features.append(pd.DataFrame(\n",
    "#                    {\"feature\":X_names, \"score\":1-p, \"grade\":cat}))\n",
    "#     dtf_features = dtf_features.sort_values([\"grade\",\"score\"], \n",
    "#                     ascending=[True,False])\n",
    "#     dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n",
    "# X_names = dtf_features[\"feature\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cat in np.unique(y):\n",
    "#    print(\"# {}:\".format(cat))\n",
    "#    print(\"  . selected features:\",\n",
    "#          len(dtf_features[dtf_features[\"grade\"]==cat]))\n",
    "#    print(\"  . top features:\", \",\".join(\n",
    "# dtf_features[dtf_features[\"grade\"]==cat][\"feature\"].values[:30]))\n",
    "#    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = feature_extraction.text.TfidfVectorizer(vocabulary=X_names)\n",
    "# vectorizer.fit(corpus)\n",
    "# X_train = vectorizer.transform(corpus)\n",
    "# dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## pipeline\n",
    "# model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "#                            (\"classifier\", classifier)])\n",
    "# ## train classifier\n",
    "# model[\"classifier\"].fit(X_train, y_train)\n",
    "# ## test\n",
    "# X_test = dtf_test[\"adjectives\"].values\n",
    "# predicted = model.predict(X_test)\n",
    "# predicted_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = np.unique(y_test)\n",
    "# y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "# y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "# auc = metrics.roc_auc_score(y_test_array, predicted_prob, \n",
    "#                             multi_class=\"one_vs_rest\")\n",
    "# print(\"Accuracy:\",  round(accuracy,2))\n",
    "# print(\"Auc:\", round(auc,2))\n",
    "# print(\"Detail:\")\n",
    "# print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = metrics.confusion_matrix(y_test, predicted)\n",
    "# fig, ax = plt.subplots()\n",
    "# sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "#             cbar=False)\n",
    "# ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "#        yticklabels=classes, title=\"Confusion matrix\")\n",
    "# plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "# for i in range(len(classes)):\n",
    "#     fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "#                            predicted_prob[:,i])\n",
    "#     ax[0].plot(fpr, tpr, lw=3, \n",
    "#               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "#                               metrics.auc(fpr, tpr))\n",
    "#                )\n",
    "# ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "# ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "#           xlabel='False Positive Rate', \n",
    "#           ylabel=\"True Positive Rate (Recall)\", \n",
    "#           title=\"Receiver operating characteristic\")\n",
    "# ax[0].legend(loc=\"lower right\")\n",
    "# ax[0].grid(True)\n",
    "\n",
    "# for i in range(len(classes)):\n",
    "#     precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "#                  y_test_array[:,i], predicted_prob[:,i])\n",
    "#     ax[1].plot(recall, precision, lw=3, \n",
    "#                label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "#                                   metrics.auc(recall, precision))\n",
    "#               )\n",
    "# ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "#           ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "# ax[1].legend(loc=\"best\")\n",
    "# ax[1].grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## select observation\n",
    "# i = 17\n",
    "# txt_instance = dtf_test[\"adjectives\"].iloc[i]\n",
    "# ## check true value and predicted value\n",
    "# print(\"True:\", y_test[i], \"--> Pred:\", predicted[i], \"| Prob:\", round(np.max(predicted_prob[i]),2))\n",
    "# ## show explanation\n",
    "# explainer = lime_text.LimeTextExplainer(class_names=\n",
    "#              np.unique(y_train))\n",
    "# explained = explainer.explain_instance(txt_instance, \n",
    "#              model.predict_proba, num_features=5)\n",
    "# explained.show_in_notebook(text=txt_instance, predict_proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {'prediction' : predicted, \n",
    "#      'actual' : y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_predictions_df = pd.DataFrame(data=d)\n",
    "# adj_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_predictions_df.to_csv('Data/adj_predictions_grades.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
